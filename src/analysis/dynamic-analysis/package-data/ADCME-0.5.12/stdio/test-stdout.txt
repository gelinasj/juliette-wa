### DYNAMIC ANALYSIS LINE IDENTIFIER ###
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

# All requested packages already installed.

/home/jack/bin/julia
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✔️] Julia path
[✘] Dynamic library path (Optional)

[Reason]
/home/jack/.julia/adcme/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/jack/.julia/adcme/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/jack/.julia/adcme/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/jack/.julia/adcme/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/jack/.julia/packages/ADCME/PJIHk/src/../deps/deps.jl
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
Load library operator (with gradient, multiple outputs = true): /home/jack/.julia/packages/ADCME/PJIHk/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.8867142286175733, 0.9944147575228686, 0.9370463037840906, 0.38356174258158116, 0.9801963736504056, 0.7203928192351912, 0.3266295072047223, 0.0023888885580767294, 0.07905482281078569, 0.07980407581325166]
Test Summary:    | Pass  Total
sparse_assembler |    3      3
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Pass  Total
trisolve      |    1      1
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_uH2EiT" --port 0
tensorboard --logdir="/tmp/jl_bx1uq6" --port 0
Test Summary: |
diary         | No tests
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
Test Summary:      | Pass  Total
control_dependency |    2      2
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/jack/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/jack/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 6, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 16, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758002], 7, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390849407169424], 19, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999996089748444], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.2999999999997658], 41, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.5511047401462164], 59, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#494"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7fede83fac20>), ADCME.var"#df#495"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7fede83fac20>), ADCME.var"#c#496"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64}([0.8867142286175733, 0.9944147575228686], Any[], Any[], 0, 0), ADCME.var"#dc#499"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64,Int64,Int64}([0.8867142286175733, 0.9944147575228686], Any[], Any[], 0, 0, 2, 0), [0.8867142286175733, 0.9944147575228686])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
iter 1, current loss = 9052.267665910374
================== STEP 0 ==================
iter 2, current loss = 8.65423941067802e11
iter 3, current loss = 2842.7749004624684
================== STEP 1 ==================
iter 4, current loss = 2671.7009365909157
iter 5, current loss = 2170.195680339636
iter 6, current loss = 4049.6437807217553
iter 7, current loss = 1954.4112894360876
================== STEP 2 ==================
iter 8, current loss = 1947.9828401638351
iter 9, current loss = 1922.374939575046
iter 10, current loss = 1796.8769526364263
iter 11, current loss = 1232.9249180764457
iter 12, current loss = 1.6122486045115045
iter 13, current loss = 7.025988266301115e-20
================== STEP 3 ==================
iter 14, current loss = 1.6450515346013333e-18
iter 15, current loss = 6.716174102468075e-20
================== STEP 4 ==================
iter 16, current loss = 8.079136590475768e-24
iter 17, current loss = 1.045327750468475e-18
iter 18, current loss = 1.4113164618280163e-29
================== STEP 5 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
iter 1, current loss = 14.815940877728695
================== STEP 0 ==================
iter 2, current loss = 8.27273605859996e7
iter 3, current loss = 14.683055627194305
iter 4, current loss = 0.7808691911554977
================== STEP 1 ==================
iter 5, current loss = 0.4997092954072236
iter 6, current loss = 0.4932244470696269
================== STEP 2 ==================
iter 7, current loss = 0.4880043258421424
iter 8, current loss = 0.46755905507994994
iter 9, current loss = 0.3833847105170825
iter 10, current loss = 4.986517513922486
iter 11, current loss = 0.3782984478358724
================== STEP 3 ==================
iter 12, current loss = 0.4242563389478009
iter 13, current loss = 0.34198646118012577
================== STEP 4 ==================
iter 14, current loss = 0.2559959943910934
iter 15, current loss = 5.704042356757626
iter 16, current loss = 0.25520642208755373
================== STEP 5 ==================
iter 17, current loss = 0.16789945760990976
iter 18, current loss = 0.07277355562180203
iter 19, current loss = 99.00132203657117
iter 20, current loss = 0.07160283575490026
================== STEP 6 ==================
iter 21, current loss = 78.1074954335224
iter 22, current loss = 0.06675056018002727
iter 23, current loss = 0.05742250597536753
================== STEP 7 ==================
iter 24, current loss = 0.029709805078327503
iter 25, current loss = 0.02637435361718798
================== STEP 8 ==================
iter 26, current loss = 0.022846942860800433
iter 27, current loss = 0.013592927477387542
iter 28, current loss = 0.7164474849307968
iter 29, current loss = 0.013433970325356022
================== STEP 9 ==================
iter 30, current loss = 0.007283676353666503
iter 31, current loss = 0.044174573997290384
iter 32, current loss = 0.005798819960010793
================== STEP 10 ==================
iter 33, current loss = 0.0022676117517579698
iter 34, current loss = 0.002100196784900777
================== STEP 11 ==================
iter 35, current loss = 0.0003602532180871637
iter 36, current loss = 0.08552062168458313
iter 37, current loss = 0.00035811537912219533
================== STEP 12 ==================
iter 38, current loss = 9.228360936576366e-5
iter 39, current loss = 0.0006698385118031021
iter 40, current loss = 1.5896938770281917e-5
================== STEP 13 ==================
iter 41, current loss = 7.69267621113192e-6
iter 42, current loss = 3.1772299270924574e-7
================== STEP 14 ==================
iter 43, current loss = 8.594146989333299e-9
iter 44, current loss = 3.3240165736628593e-6
iter 45, current loss = 6.578967526180274e-10
================== STEP 15 ==================
iter 46, current loss = 1.387279915371432e-12
iter 47, current loss = 9.351650856896816e-9
iter 48, current loss = 1.925608688170897e-14
================== STEP 16 ==================
iter 49, current loss = 6.383731034930323e-19
iter 50, current loss = 2.6042598745511037e-22
================== STEP 17 ==================
iter 51, current loss = 2.2938596009629734e-29
iter 52, current loss = 4.163833271062382e-21
iter 53, current loss = 4.979684464207637e-30
================== STEP 18 ==================
iter 1, current loss = 14.815940877728695
================== STEP 0 ==================
iter 2, current loss = 247118.3973769921
iter 3, current loss = 12.85046093912433
iter 4, current loss = 0.737740638653728
================== STEP 1 ==================
iter 5, current loss = 0.6250101289464969
iter 6, current loss = 0.49314251650848284
================== STEP 2 ==================
iter 7, current loss = 0.49208797856777087
iter 8, current loss = 0.4122150056910494
================== STEP 3 ==================
iter 9, current loss = 26.698823710109075
iter 10, current loss = 0.4055979754319386
iter 11, current loss = 1.365969936214344
iter 12, current loss = 0.3744303679678075
iter 13, current loss = 0.2216777274567389
iter 14, current loss = 0.23435508284869205
================== STEP 4 ==================
iter 15, current loss = 0.31819511741133655
iter 16, current loss = 0.21883311385693743
================== STEP 5 ==================
iter 17, current loss = 0.2185701062522939
iter 18, current loss = 0.20779133354100682
================== STEP 6 ==================
iter 19, current loss = 0.1718211251623302
iter 20, current loss = 0.10664779097063148
================== STEP 7 ==================
iter 21, current loss = 0.1019145220034648
iter 22, current loss = 0.09008754985539559
================== STEP 8 ==================
iter 23, current loss = 0.07083021166733824
iter 24, current loss = 1.0105705764152009
iter 25, current loss = 0.0827793167424216
iter 26, current loss = 0.048945076232933225
iter 27, current loss = 0.04988374883440221
================== STEP 9 ==================
iter 28, current loss = 229.69228354306932
iter 29, current loss = 0.0493915852768132
iter 30, current loss = 0.27547981632750457
iter 31, current loss = 0.03988734488189967
================== STEP 10 ==================
iter 32, current loss = 0.03985362058391739
iter 33, current loss = 0.03369965111193118
================== STEP 11 ==================
iter 34, current loss = 0.031045003362362843
iter 35, current loss = 0.01632979683279001
================== STEP 12 ==================
iter 36, current loss = 0.016013282584732044
iter 37, current loss = 0.011516444203831588
================== STEP 13 ==================
iter 38, current loss = 0.005932639209589364
iter 39, current loss = 0.0005686855235063287
================== STEP 14 ==================
iter 40, current loss = 0.000498919971855448
iter 41, current loss = 0.0004129993563331541
================== STEP 15 ==================
iter 42, current loss = 0.00029602154963906824
iter 43, current loss = 7.028465677474268e-6
================== STEP 16 ==================
iter 44, current loss = 6.063213397432192e-6
iter 45, current loss = 5.097819555359473e-6
================== STEP 17 ==================
iter 46, current loss = 4.940548562777126e-6
iter 47, current loss = 1.890767875091919e-9
================== STEP 18 ==================
iter 48, current loss = 5.169358745533785e-9
iter 49, current loss = 9.973267437216641e-10
================== STEP 19 ==================
iter 50, current loss = 9.83813851177996e-10
iter 51, current loss = 9.532364226746193e-10
================== STEP 20 ==================
iter 52, current loss = 9.530653459551067e-10
iter 53, current loss = 6.144339608951119e-17
================== STEP 21 ==================
iter 54, current loss = 3.1313707131589663e-12
iter 55, current loss = 4.719086749204249e-17
================== STEP 22 ==================
iter 56, current loss = 4.718295720846347e-17
iter 57, current loss = 7.640221840714943e-18
================== STEP 23 ==================
iter 58, current loss = 2.0525883807677737e-17
iter 59, current loss = 7.583543800473226e-18
================== STEP 24 ==================
iter 60, current loss = 7.215629392519573e-18
iter 61, current loss = 1.1378140196835921e-25
================== STEP 25 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[2.687340311058956, 2.2848777584058286, 1.9594851778940723, 1.695402405085309, 1.480263493197685, 1.3043185081551039, 1.1598475045894157, 1.0407152651051803, 0.9420302552703157, 0.8598815076342152]
[2.687340311058956, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.480263454379844, 1.3043184684311484, 1.1598474654062378, 1.0407152273674067, 0.9420302195019172, 0.8598814740954399]
[2.687340311058956, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722337, 1.7903868796137, 1.666533106551471, 1.5498999348193685, 1.4403938823398204]
[2.687340311058956, 2.5196803722971532, 2.3591806721463433, 2.2059490607905308, 2.060059325290666, 1.921544648411781, 1.7903894445161121, 1.6665356793266157, 1.5499024452536936, 1.4403964019318742]
[2.687340311058956, 2.519680334828145, 2.407655825231478, 2.3197815374114255, 2.246150283167248, 2.182163783773478, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252]
[2.687340311058956, 2.5289466959494193, 2.420490642269894, 2.3345738165870626, 2.262184980528145, 2.1990517443624436, 2.1427536022001736, 2.0917631683139017, 2.0450438762274734, 2.001854279772373]
[2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956]
[2.687340311058956, 2.6872637777504984, 2.687186271558512, 2.6871081082446744, 2.6870294441458276, 2.6869503723706383, 2.6868709546007827, 2.6867912346415768, 2.686711245167153, 2.6866310114542364]
ADCME.Optimizer.RMSProp: 
[2.687340311058956, 2.1809229506849572, 1.8767079801297724, 1.6546592408302834, 1.4792440330627719, 1.334696176675614, 1.212439851596489, 1.1071870862263171, 1.0154089446876469, 0.9346163191023282]
ADCME.Optimizer.AMSGrad: 
[2.687340311058956, 2.1809312707347455, 1.6124928714759128, 1.1086151780363889, 0.7379095523937292, 0.5260637392759809, 0.45851612395000907, 0.4877499962958967, 0.5512317022689823, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.687340311058956, 2.442570256533514, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870794, 1.3669096060903076]
ADCME.Optimizer.Momentum: 
[2.687340311058956, 0.5561138694752266, 1.9019191744859019, 1.5251751312785737, 0.0420157941282293, 1.1070655728753587, 0.9972859136071748, 0.09250596740575295, 0.8373703084967704, 0.9155307151492695]
ADCME.Optimizer.Nesterov: 
[2.687340311058956, 1.9593498023002809, 1.2701537117986892, 0.7838060906690361, 0.5406336834135216, 0.4889865362290184, 0.5361697434507272, 0.593802848884102, 0.6052577936273842, 0.5531368580544891]
ADCME.Optimizer.RADAM: 
[2.687340311058956, 2.2848777584058286, 1.94323977812989, 1.6552856125616953, 1.4144226819237642, 1.4126078826685302, 1.4099249144610229, 1.4065453158264798, 1.4025672017224884, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.687340311058956, 2.51968033219294, 2.362208211311266, 2.2144819560814186, 2.0760592333976766, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.606666358477995, 1.5082598767767736]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
Test Summary: | Pass  Total
ActNorm       |    2      2
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Broken  Total
NeuralCouplingFlow |      1      1
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
Finite difference: [0.338304969149429, 0.03110668900153213, 0.0030844134168096296, 0.00030817976702797873, 3.0815361936126234e-5]
Automatic differentiation: [0.03130553233926808, 0.0003032588069560432, 3.0228002121568083e-6, 3.0218215111945415e-8, 3.021723215176822e-10]
Test Summary: | Pass  Total
test_jacobian |    1      1
Test Summary: | Pass  Total
lineview      |    1      1
Test Summary: | Pass  Total
meshview      |    2      2
Test Summary: | Pass  Total
gradview      |    1      1
Test Summary: | Pass  Total
jacview       |    1      1
Test Summary: |
PCLview       | No tests
Test Summary: | Pass  Total
animate       |    1      1
