### DYNAMIC ANALYSIS LINE IDENTIFIER ###
Collecting package metadata (current_repodata.json): ...working... done
Solving environment: ...working... done

# All requested packages already installed.

/home/jack/bin/julia
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✔️] Julia path
[✘] Dynamic library path (Optional)

[Reason]
/home/jack/.julia/adcme/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/jack/.julia/adcme/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/jack/.julia/adcme/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/jack/.julia/adcme/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/jack/.julia/packages/ADCME/PJIHk/src/../deps/deps.jl
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
Load library operator (with gradient, multiple outputs = true): /home/jack/.julia/packages/ADCME/PJIHk/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.1704091807753476, 0.04867988446967075, 0.5173154529653547, 0.7141375816936386, 0.056527036236753814, 0.8226830043940814, 0.2806188198081061, 0.7777644831438899, 0.1149823738655189, 0.9876542630398597]
Test Summary:    | Pass  Total
sparse_assembler |    3      3
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Pass  Total
trisolve      |    1      1
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_WevWyK" --port 0
tensorboard --logdir="/tmp/jl_2OUZKX" --port 0
Test Summary: |
diary         | No tests
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
Test Summary:      | Pass  Total
control_dependency |    2      2
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/jack/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/jack/.julia/packages/ADCME/PJIHk/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 8, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 15, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758003], 9, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390854229866918], 17, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999996375120652], 18, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.2999999999998604], 43, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.45840750163141003], 25, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#494"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f995c111950>), ADCME.var"#df#495"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f995c111950>), ADCME.var"#c#496"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64}([0.1704091807753476, 0.04867988446967075], Any[], Any[], 0, 0), ADCME.var"#dc#499"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64,Int64,Int64}([0.1704091807753476, 0.04867988446967075], Any[], Any[], 0, 0, 2, 0), [0.1704091807753476, 0.04867988446967075])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
iter 1, current loss = 10215.293543931162
================== STEP 0 ==================
iter 2, current loss = 8.669539015552817e11
iter 3, current loss = 3798.9062840166453
================== STEP 1 ==================
iter 4, current loss = 3456.621545045392
iter 5, current loss = 2460.5368233804156
iter 6, current loss = 6433.414836336521
iter 7, current loss = 2052.835185569269
================== STEP 2 ==================
iter 8, current loss = 2046.1982483496759
iter 9, current loss = 2019.7579613040448
iter 10, current loss = 1890.1356100616363
iter 11, current loss = 1306.500953493271
iter 12, current loss = 0.25516174346369047
iter 13, current loss = 6.691907553513938e-19
================== STEP 3 ==================
iter 14, current loss = 3.799942423723356e-18
iter 15, current loss = 5.673659839864355e-19
================== STEP 4 ==================
iter 16, current loss = 4.146066413067592e-21
iter 17, current loss = 7.241480072832095e-18
iter 18, current loss = 2.254853025463771e-29
================== STEP 5 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
iter 1, current loss = 0.7724643091881169
================== STEP 0 ==================
iter 2, current loss = 8.356000202805118e7
iter 3, current loss = 0.7676596317446097
iter 4, current loss = 0.01902829478404104
================== STEP 1 ==================
iter 5, current loss = 0.017514637349968686
iter 6, current loss = 0.038537419720632585
iter 7, current loss = 0.01751032784605838
================== STEP 2 ==================
iter 8, current loss = 0.01748857231283667
iter 9, current loss = 0.01740170340167993
iter 10, current loss = 0.01697105253327718
iter 11, current loss = 0.014913038392738382
iter 12, current loss = 0.007908262736535103
iter 13, current loss = 0.5068266934696662
iter 14, current loss = 0.007769859005574327
================== STEP 3 ==================
iter 15, current loss = 0.003713975225938676
iter 16, current loss = 0.08635284579975126
iter 17, current loss = 0.0035220349446153125
================== STEP 4 ==================
iter 18, current loss = 0.000812065990096683
iter 19, current loss = 0.0008035624253802083
================== STEP 5 ==================
iter 20, current loss = 9.247222935271926e-5
iter 21, current loss = 0.02730664614504784
iter 22, current loss = 9.228208147227539e-5
================== STEP 6 ==================
iter 23, current loss = 1.5732611949231148e-5
iter 24, current loss = 0.0002729171557759541
iter 25, current loss = 7.632730062529692e-7
================== STEP 7 ==================
iter 26, current loss = 1.9193157115682842e-8
iter 27, current loss = 1.1274709820350171e-5
iter 28, current loss = 1.8571571567035732e-8
================== STEP 8 ==================
iter 29, current loss = 1.8070977343252928e-9
iter 30, current loss = 7.26166050389916e-13
================== STEP 9 ==================
iter 31, current loss = 3.626023384751872e-17
iter 32, current loss = 1.3812109406786792e-19
================== STEP 10 ==================
iter 33, current loss = 2.631898824801821e-27
iter 34, current loss = 1.145080907734875e-29
================== STEP 11 ==================
iter 1, current loss = 0.7724643091881169
================== STEP 0 ==================
iter 2, current loss = 61285.642705453276
iter 3, current loss = 0.5770352166221108
================== STEP 1 ==================
iter 4, current loss = 0.5465304694476416
iter 5, current loss = 0.01833472678699672
================== STEP 2 ==================
iter 6, current loss = 0.018057262001340026
iter 7, current loss = 0.017498242966090247
================== STEP 3 ==================
iter 8, current loss = 0.01749381831694976
iter 9, current loss = 0.0038656610606297576
================== STEP 4 ==================
iter 10, current loss = 3292.735073036308
iter 11, current loss = 0.0037632421721948313
iter 12, current loss = 0.0003811489026556037
================== STEP 5 ==================
iter 13, current loss = 0.0003656372570549112
iter 14, current loss = 0.0003431695629629204
================== STEP 6 ==================
iter 15, current loss = 0.00032368971013271337
iter 16, current loss = 1.9401966267485516e-5
================== STEP 7 ==================
iter 17, current loss = 2.4591942719464357e-5
iter 18, current loss = 7.677291808009474e-6
================== STEP 8 ==================
iter 19, current loss = 7.525059379133682e-6
iter 20, current loss = 7.236485742688513e-6
================== STEP 9 ==================
iter 21, current loss = 7.23522095405469e-6
iter 22, current loss = 4.0990582835877613e-10
================== STEP 10 ==================
iter 23, current loss = 7.465259237090401e-5
iter 24, current loss = 7.809312330521214e-11
================== STEP 11 ==================
iter 25, current loss = 7.807692590390317e-11
iter 26, current loss = 6.888495849032182e-11
================== STEP 12 ==================
iter 27, current loss = 1.493050247656226e-9
iter 28, current loss = 1.0884025340359714e-17
================== STEP 13 ==================
iter 29, current loss = 1.060604386842529e-17
iter 30, current loss = 8.53772362911693e-18
================== STEP 14 ==================
iter 31, current loss = 8.482563310680821e-18
iter 32, current loss = 8.343045187817475e-18
================== STEP 15 ==================
iter 33, current loss = 8.341443165743423e-18
iter 34, current loss = 5.931826506039201e-17
iter 35, current loss = 1.4756023970993854e-20
================== STEP 16 ==================
iter 36, current loss = 2.929478480359205e-15
iter 37, current loss = 1.2449211160519093e-30
================== STEP 17 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[2.687340311058956, 2.2848777584058286, 1.9594851778940723, 1.695402405085309, 1.480263493197685, 1.3043185081551039, 1.1598475045894157, 1.0407152651051803, 0.9420302552703157, 0.8598815076342152]
[2.687340311058956, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.480263454379844, 1.3043184684311484, 1.1598474654062378, 1.0407152273674067, 0.9420302195019172, 0.8598814740954399]
[2.687340311058956, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722337, 1.7903868796137, 1.666533106551471, 1.5498999348193685, 1.4403938823398204]
[2.687340311058956, 2.5196803722971532, 2.3591806721463433, 2.2059490607905308, 2.060059325290666, 1.921544648411781, 1.7903894445161121, 1.6665356793266157, 1.5499024452536936, 1.4403964019318742]
[2.687340311058956, 2.519680334828145, 2.407655825231478, 2.3197815374114255, 2.246150283167248, 2.182163783773478, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252]
[2.687340311058956, 2.5289466959494193, 2.420490642269894, 2.3345738165870626, 2.262184980528145, 2.1990517443624436, 2.1427536022001736, 2.0917631683139017, 2.0450438762274734, 2.001854279772373]
[2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956]
[2.687340311058956, 2.6872637777504984, 2.687186271558512, 2.6871081082446744, 2.6870294441458276, 2.6869503723706383, 2.6868709546007827, 2.6867912346415768, 2.686711245167153, 2.6866310114542364]
ADCME.Optimizer.RMSProp: 
[2.687340311058956, 2.1809229506849572, 1.8767079801297724, 1.6546592408302834, 1.4792440330627719, 1.334696176675614, 1.212439851596489, 1.1071870862263171, 1.0154089446876469, 0.9346163191023282]
ADCME.Optimizer.AMSGrad: 
[2.687340311058956, 2.1809312707347455, 1.6124928714759128, 1.1086151780363889, 0.7379095523937292, 0.5260637392759809, 0.45851612395000907, 0.4877499962958967, 0.5512317022689823, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.687340311058956, 2.442570256533514, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870794, 1.3669096060903076]
ADCME.Optimizer.Momentum: 
[2.687340311058956, 0.5561138694752266, 1.9019191744859019, 1.5251751312785737, 0.0420157941282293, 1.1070655728753587, 0.9972859136071748, 0.09250596740575295, 0.8373703084967704, 0.9155307151492695]
ADCME.Optimizer.Nesterov: 
[2.687340311058956, 1.9593498023002809, 1.2701537117986892, 0.7838060906690361, 0.5406336834135216, 0.4889865362290184, 0.5361697434507272, 0.593802848884102, 0.6052577936273842, 0.5531368580544891]
ADCME.Optimizer.RADAM: 
[2.687340311058956, 2.2848777584058286, 1.94323977812989, 1.6552856125616953, 1.4144226819237642, 1.4126078826685302, 1.4099249144610229, 1.4065453158264798, 1.4025672017224884, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.687340311058956, 2.51968033219294, 2.362208211311266, 2.2144819560814186, 2.0760592333976766, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.606666358477995, 1.5082598767767736]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
Test Summary: | Pass  Total
ActNorm       |    2      2
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Broken  Total
NeuralCouplingFlow |      1      1
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
Finite difference: [0.21461329446014624, 0.020241299213045405, 0.0020124423634118615, 0.00020112784832061382, 2.0111621436810544e-5]
Automatic differentiation: [0.016064081251326065, 0.0001530048429148178, 1.5225318367784643e-6, 1.5217814307481934e-8, 1.5217054650258834e-10]
Test Summary: | Pass  Total
test_jacobian |    1      1
Test Summary: | Pass  Total
lineview      |    1      1
Test Summary: | Pass  Total
meshview      |    2      2
Test Summary: | Pass  Total
gradview      |    1      1
Test Summary: | Pass  Total
jacview       |    1      1
Test Summary: |
PCLview       | No tests
Test Summary: | Pass  Total
animate       |    1      1
