1c1 < -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /home/jack/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /home/jack/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jack/.julia/packages/ADCME/DBZ10/deps/CustomOps/build [1/17] Building CXX object CMakeFiles/adcme.dir/OT/src/sinkhorn.cpp.o [2/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/Impl.cpp.o [3/17] Building CXX object CMakeFiles/adcme.dir/SparseToDense/SparseToDense.cpp.o [4/17] Building CXX object CMakeFiles/adcme.dir/SparseAccumulate/SparseAccumulator.cpp.o [5/17] Building CXX object CMakeFiles/adcme.dir/TriLu/TriLu.cpp.o [6/17] Building CXX object CMakeFiles/adcme.dir/SparseConcate/SparseConcate.cpp.o [7/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/lru_cache.cpp.o [8/17] Building CXX object CMakeFiles/adcme.dir/SparseScatterUpdate/SparseScatterUpdate.cpp.o [9/17] Building CXX object CMakeFiles/adcme.dir/OT/SinkhornKnopp/SinkhornKnopp.cpp.o [10/17] Building CXX object CMakeFiles/adcme.dir/SparseIndexing/SparseIndexing.cpp.o [11/17] Building CXX object CMakeFiles/adcme.dir/SparseMatMul/SparseMatMul.cpp.o [12/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Solve/Solve.cpp.o [13/17] Building CXX object CMakeFiles/adcme.dir/SolveBatchedRhs/SolveBatchedRhs.cpp.o [14/17] Building CXX object CMakeFiles/adcme.dir/SparseFactorizationSolve/Factorization/SparseFactorization.cpp.o [15/17] Building CXX object CMakeFiles/adcme.dir/SparseLeastSquare/SparseLeastSquare.cpp.o [16/17] Building CXX object CMakeFiles/adcme.dir/SparseSolver/SparseSolver.cpp.o [17/17] Linking CXX shared library libadcme.so /home/jack/bin/julia -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /home/jack/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /home/jack/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jack/.julia/conda/3/lib/Adept-2/adept/build [1/12] Building CXX object CMakeFiles/adept.dir/StackStorageOrig.cpp.o [2/12] Building CXX object CMakeFiles/adept.dir/cppblas.cpp.o [3/12] Building CXX object CMakeFiles/adept.dir/settings.cpp.o [4/12] Building CXX object CMakeFiles/adept.dir/Storage.cpp.o [5/12] Building CXX object CMakeFiles/adept.dir/index.cpp.o [6/12] Building CXX object CMakeFiles/adept.dir/Array.cpp.o [7/12] Building CXX object CMakeFiles/adept.dir/Stack.cpp.o [8/12] Building CXX object CMakeFiles/adept.dir/inv.cpp.o [9/12] Building CXX object CMakeFiles/adept.dir/vector_utilities.cpp.o [10/12] Building CXX object CMakeFiles/adept.dir/jacobian.cpp.o [11/12] Building CXX object CMakeFiles/adept.dir/solve.cpp.o [12/12] Linking CXX shared library /home/jack/.julia/conda/3/lib/libadept.so -- The C compiler identification is GNU 5.4.0 -- The CXX compiler identification is GNU 5.4.0 -- Detecting C compiler ABI info -- Detecting C compiler ABI info - done -- Check for working C compiler: /home/jack/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-gcc - skipped -- Detecting C compile features -- Detecting C compile features - done -- Detecting CXX compiler ABI info -- Detecting CXX compiler ABI info - done -- Check for working CXX compiler: /home/jack/.julia/conda/3/bin/x86_64-conda_cos6-linux-gnu-g++ - skipped -- Detecting CXX compile features -- Detecting CXX compile features - done -- Configuring done -- Generating done -- Build files have been written to: /home/jack/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build [1/2] Building CXX object CMakeFiles/ExtendedNn.dir/ExtendedNn.cpp.o [2/2] Linking CXX shared library libExtendedNn.so [✔️] Julia version [✔️] TensorFlow version [✔️] TensorFlow-Probability version [✔️] Python executable file [✔️] Julia path [✘] Dynamic library path (Optional) [Reason] /home/jack/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you. [Instruction] Add your dynamic library path path to your environment path, e.g. (Unix systems) export LD_LIBRARY_PATH=/home/jack/.julia/conda/3/lib:$LD_LIBRARY_PATH For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple). For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH. [✔️] Memory Address Length = 64 [✘] Binaries path [Reason] /home/jack/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal. However, setting the path is NOT a requirement, and ADCME works totally fine without any action. [Instruction] (Optional) Add your binary path to your environment path, e.g. (Unix systems) export PATH=/home/jack/.julia/conda/3/bin:$PATH For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple). For Windows, you need to add it to system environment. [✘] GPU Support (Optional) [Reason] ADCME is not compiled against GPU. [Instruction] If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME. Dependency file is located at: /home/jack/.julia/packages/ADCME/DBZ10/src/../deps/deps.jl Test Summary: | Pass Total indexing for rank 3 tensors | 3 3 ∘ Add the following lines to CMakeLists.txt include_directories(${LIBDIR}/Adept-2/include) find_library(ADEPT_LIB_FILE adept HINTS ${LIBDIR}) find_library(LIBOPENBLAS openblas HINTS ${LIBDIR}) message("ADEPT_LIB_FILE=${ADEPT_LIB_FILE}") message("LIBOPENBLAS=${LIBOPENBLAS}") ∘ Add `${ADEPT_LIB_FILE}` and `${LIBOPENBLAS}` to `target_link_libraries` Load library operator (with gradient, multiple outputs = true): /home/jack/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn Test Summary: | Pass Total fcx | 4 4 Test Summary: | Pass Total dropout | 2 2 Test Summary: | Pass Total sparse_constructor | 7 7 Test Summary: | Pass Total sparse_arithmetic | 4 4 Test Summary: | Pass Total sparse_adjoint | 1 1 Test Summary: | Pass Total sparse_mul | 6 6 Test Summary: | Pass Total sparse_vcat_hcat | 2 2 Test Summary: | Pass Total sparse_indexing | 3 3 Test Summary: | Pass Total sparse_solve | 1 1 k = 1 k = 2 k = 3 k = 4 k = 5 k = 6 k = 7 k = 8 k = 9 k = 10 v = [0.2538952136361792, 0.9556797651016742, 0.9690149574758229, 0.521676401225629, 0.2453650941074792, 0.5133217153024039, 0.6101356897300187, 0.5092385699712374, 0.45281061078859164, 0.2934747969865863] Test Summary: | Pass Total sparse_assembler | 3 3 Test Summary: | Pass Total sparse_least_square | 1 1 Test Summary: | Pass Total sparse mat mul | 3 3 Test Summary: | Pass Total spdiag | 3 3 Test Summary: | Pass Total spzero | 2 2 Test Summary: | Pass Total sparse indexing | 1 1 Test Summary: | Pass Total sum | 3 3 Test Summary: | Pass Total dense_to_sparse | 2 2 Test Summary: | Pass Total spdiagm | 4 4 Test Summary: | Pass Total hvcat | 1 1 Test Summary: | Pass Total find | 6 6 Test Summary: | Pass Total sparse scatter update add | 2 2 Test Summary: | Pass Total constant sparse | 1 1 Test Summary: | Pass Total get index | 1 1 Test Summary: | Pass Total sparse_factorization_and_solve | 2 2 Test Summary: | Pass Total sparse solver warning | 1 1 Test Summary: | Pass Total sparse promote | 6 6 Test Summary: | Broken Total random | 47 47 Test Summary: | Pass Total save and load | 1 1 Test Summary: | Pass Total psave and pload | 1 1 tensorboard --logdir="/tmp/jl_LlXQiZ" --port 0 tensorboard --logdir="/tmp/jl_5hZnA9" --port 0 Test Summary: | diary | No tests Test Summary: | Pass Total indexing | 28 28 Test Summary: | Pass Total Variables | 4 4 Test Summary: | Pass Total tensor | 2 2 Test Summary: | Pass Total Hessian | 2 2 Test Summary: | Pass Total Jacobian | 1 1 Test Summary: | Pass Total gradients_v | 1 1 Test Summary: | Pass Total size and length | 9 9 Test Summary: | Pass Total copy | 1 1 Test Summary: | Pass Total getindex | 1 1 Test Summary: | Pass Total convert_to_tensor | 5 5 Test Summary: | Pass Total cell | 2 2 Test Summary: | Pass Total special matrices | 2 2 Test Summary: | Pass Total ones/zeros like | 2 2 Test Summary: | Pass Total gradient_magnitude | 1 1 Test Summary: | Pass Total indexing with tensor | 6 6 Test Summary: | Pass Total ndims | 4 4 Test Summary: | Pass Total gradients_colocate | 1 1 Test Summary: | Pass Total analyze-package.jl getDiff.sh nohup.out override-core package-data package-data-tst README.md run.sh test-package.jl tests utils.jl | 27 27 Test Summary: | Pass Total reshape | 6 6 Test Summary: | Pass Total scatter_update | 9 9 Test Summary: | Pass Total adjoint | 4 4 Test Summary: | Pass Total scatter_update_pyobject | 9 9 Test Summary: | Pass Total Operators | 14 14 Test Summary: | Pass Total Other Operators | 1 1 Test Summary: | Pass Total Concat and stack | 6 6 Test Summary: | Pass Total Vectorize | 5 5 Test Summary: | Pass Total Solve | 3 3 Test Summary: | Pass Total diff | 3 3 Test Summary: | Pass Total clip | 1 1 Test Summary: | Pass Total map | 1 1 Test Summary: | Pass Total diag | 2 2 Test Summary: | Pass Total dot | 3 3 Test Summary: | Pass Total prod | 1 1 Test Summary: | Pass Total findall | 2 2 Test Summary: | Pass Total svd | 1 1 Test Summary: | Pass Total vector | 1 1 Test Summary: | Pass Total repeat | 6 6 pmap: Error During Test at /home/jack/.julia/packages/ADCME/DBZ10/test/ops.jl:336 Got exception outside of a @test UndefVarError: pmap not defined Stacktrace: [1] top-level scope at /home/jack/.julia/packages/ADCME/DBZ10/test/ops.jl:338 [2] top-level scope at /buildworker/worker/package_linux64/build/usr/share/julia/stdlib/v1.5/Test/src/Test.jl:1115 [3] top-level scope at /home/jack/.julia/packages/ADCME/DBZ10/test/ops.jl:337 [4] include(::String) at ./client.jl:457 [5] top-level scope at /home/jack/.julia/packages/ADCME/DBZ10/test/runtests.jl:28 [6] include(::String) at ./client.jl:457 [7] top-level scope at none:11 [8] eval(::Module, ::Any) at ./boot.jl:331 [9] exec_options(::Base.JLOptions) at ./client.jl:272 [10] _start() at ./client.jl:506 Test Summary: | Error Total pmap | 1 1 --- > /home/jack/bin/julia [✔️] Julia version [✔️] TensorFlow version [✔️] TensorFlow-Probability version [✔️] Python executable file [✔️] Julia path [✘] Dynamic library path (Optional) [Reason] /home/jack/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you. [Instruction] Add your dynamic library path path to your environment path, e.g. (Unix systems) export LD_LIBRARY_PATH=/home/jack/.julia/conda/3/lib:$LD_LIBRARY_PATH For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple). For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH. [✔️] Memory Address Length = 64 [✘] Binaries path [Reason] /home/jack/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal. However, setting the path is NOT a requirement, and ADCME works totally fine without any action. [Instruction] (Optional) Add your binary path to your environment path, e.g. (Unix systems) export PATH=/home/jack/.julia/conda/3/bin:$PATH For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple). For Windows, you need to add it to system environment. [✘] GPU Support (Optional) [Reason] ADCME is not compiled against GPU. [Instruction] If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME. Dependency file is located at: /home/jack/.julia/packages/ADCME/DBZ10/src/../deps/deps.jl Test Summary: | Pass Total indexing for rank 3 tensors | 3 3 Load library operator (with gradient, multiple outputs = true): /home/jack/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn Test Summary: | Pass Total fcx | 4 4 Test Summary: | Pass Total dropout | 2 2 Test Summary: | Pass Total sparse_constructor | 7 7 Test Summary: | Pass Total sparse_arithmetic | 4 4 Test Summary: | Pass Total sparse_adjoint | 1 1 Test Summary: | Pass Total sparse_mul | 6 6 Test Summary: | Pass Total sparse_vcat_hcat | 2 2 Test Summary: | Pass Total sparse_indexing | 3 3 Test Summary: | Pass Total sparse_solve | 1 1 k = 1 k = 2 k = 3 k = 4 k = 5 k = 6 k = 7 k = 8 k = 9 k = 10 v = [0.800488384024882, 0.8241024666947354, 0.26054113162986714, 0.6668425422755024, 0.3084987249854121, 0.11581118335453278, 0.0051215798889825415, 0.05803861014365608, 0.5372324125477215, 0.27534744242934295] Test Summary: | Pass Total sparse_assembler | 3 3 Test Summary: | Pass Total sparse_least_square | 1 1 Test Summary: | Pass Total sparse mat mul | 3 3 Test Summary: | Pass Total spdiag | 3 3 Test Summary: | Pass Total spzero | 2 2 Test Summary: | Pass Total sparse indexing | 1 1 Test Summary: | Pass Total sum | 3 3 Test Summary: | Pass Total dense_to_sparse | 2 2 Test Summary: | Pass Total spdiagm | 4 4 Test Summary: | Pass Total hvcat | 1 1 Test Summary: | Pass Total find | 6 6 Test Summary: | Pass Total sparse scatter update add | 2 2 Test Summary: | Pass Total constant sparse | 1 1 Test Summary: | Pass Total get index | 1 1 Test Summary: | Pass Total sparse_factorization_and_solve | 2 2 Test Summary: | Pass Total sparse solver warning | 1 1 Test Summary: | Pass Total sparse promote | 6 6 Test Summary: | Broken Total random | 47 47 Test Summary: | Pass Total save and load | 1 1 Test Summary: | Pass Total psave and pload | 1 1 tensorboard --logdir="/tmp/jl_ismSf4" --port 0 tensorboard --logdir="/tmp/jl_RULZGi" --port 0 Test Summary: | diary | No tests Test Summary: | Pass Total indexing | 28 28 Test Summary: | Pass Total Variables | 4 4 Test Summary: | Pass Total tensor | 2 2 Test Summary: | Pass Total Hessian | 2 2 Test Summary: | Pass Total Jacobian | 1 1 Test Summary: | Pass Total gradients_v | 1 1 Test Summary: | Pass Total size and length | 9 9 Test Summary: | Pass Total copy | 1 1 Test Summary: | Pass Total getindex | 1 1 Test Summary: | Pass Total convert_to_tensor | 5 5 Test Summary: | Pass Total cell | 2 2 Test Summary: | Pass Total special matrices | 2 2 Test Summary: | Pass Total ones/zeros like | 2 2 Test Summary: | Pass Total gradient_magnitude | 1 1 Test Summary: | Pass Total indexing with tensor | 6 6 Test Summary: | Pass Total ndims | 4 4 Test Summary: | Pass Total gradients_colocate | 1 1 Test Summary: | Pass Total analyze-package.jl getDiff.sh nohup.out override-core package-data package-data-tst README.md run.sh test-package.jl tests utils.jl | 27 27 Test Summary: | Pass Total reshape | 6 6 Test Summary: | Pass Total scatter_update | 9 9 Test Summary: | Pass Total adjoint | 4 4 Test Summary: | Pass Total scatter_update_pyobject | 9 9 Test Summary: | Pass Total Operators | 14 14 Test Summary: | Pass Total Other Operators | 1 1 Test Summary: | Pass Total Concat and stack | 6 6 Test Summary: | Pass Total Vectorize | 5 5 Test Summary: | Pass Total Solve | 3 3 Test Summary: | Pass Total diff | 3 3 Test Summary: | Pass Total clip | 1 1 Test Summary: | Pass Total map | 1 1 Test Summary: | Pass Total diag | 2 2 Test Summary: | Pass Total dot | 3 3 Test Summary: | Pass Total prod | 1 1 Test Summary: | Pass Total findall | 2 2 Test Summary: | Pass Total svd | 1 1 Test Summary: | Pass Total vector | 1 1 Test Summary: | Pass Total repeat | 6 6 Test Summary: | Pass Total pmap | 3 3 Test Summary: | Pass Total reshape | 1 1 Test Summary: | Pass Total batch mul | 1 1 Test Summary: | Pass Total sort | 2 2 Test Summary: | Pass Total set_shape | 3 3 Test Summary: | Pass Total activation | 8 8 Test Summary: | Pass Total trace | 1 1 Test Summary: | Pass Total trilu | 22 22 Test Summary: | Pass Total reverse | 3 3 Test Summary: | Pass Total solve batch | 2 2 Test Summary: | Pass Total control_dependency | 2 2 Test Summary: | Pass Total while loop | 3 3 Test Summary: | Pass Total if_clause | 1 1 Test Summary: | Pass Total if_else: tf.where | 2 2 Test Summary: | Pass Total get and add collection | 1 1 Test Summary: | Pass Total has_gpu | 1 1 Test Summary: | timeline | No tests Test Summary: | Pass Total independent | 1 1 Test Summary: | Pass Total run corner cases | 1 1 Test Summary: | Pass Total @cpu @gpu | 4 4 Test Summary: | Pass Total xavier_init | 1 1 Load library operator: /home/jack/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver Load library operator (with gradient, multiple outputs = false): /home/jack/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver Test Summary: | Pass Total load_op | 2 2 Test Summary: | Pass Total ae | 1 1 Test Summary: | Pass Total register | 4 4 Test Summary: | Pass Total list_physical_devices | 1 1 ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 6, true) ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 20, true) ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758003], 12, true) ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390848761928382], 19, true) ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999995492491696], 21, true) ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.2999999999998577], 43, true) ((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.5511047401462246], 64, true) Test Summary: | Pass Total newton raphson with linesearch | 7 7 [CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0 [CustomOptimizer] Total number of variables = 4 Test Summary: | Pass Total NLopt | 1 1 [CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0 [CustomOptimizer] Total number of variables = 2 [CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer (f, df, c, dc, x0) = (ADCME.var"#f#468"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f227809d5f0>), ADCME.var"#df#469"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f227809d5f0>), ADCME.var"#c#470"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64}([0.800488384024882, 0.8241024666947354], Any[], Any[], 0, 0), ADCME.var"#dc#473"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64,Int64,Int64}([0.800488384024882, 0.8241024666947354], Any[], Any[], 0, 0, 2, 0), [0.800488384024882, 0.8241024666947354]) Test Summary: | Pass Total Optim | 1 1 Test Summary: | Broken Total newton raphson | 1 1 Test Summary: | Broken Total NonlinearConstrainedProblem | 1 1 iter 1, current loss = 10481.16513405056 ================== STEP 0 ================== iter 2, current loss = 8.674680614136826e11 iter 3, current loss = 3994.6117195767524 ================== STEP 1 ================== iter 4, current loss = 3593.758825208133 iter 5, current loss = 2430.0215441052264 iter 6, current loss = 7163.518251508293 iter 7, current loss = 1961.3930444755933 ================== STEP 2 ================== iter 8, current loss = 1955.0864884167065 iter 9, current loss = 1929.96181628879 iter 10, current loss = 1806.775706232354 iter 11, current loss = 1251.7764205288852 iter 12, current loss = 0.061606479303160704 iter 13, current loss = 1.667102312426696e-20 ================== STEP 3 ================== iter 14, current loss = 5.505696003109266e-18 iter 15, current loss = 1.6550181300167233e-20 ================== STEP 4 ================== Test Summary: | Pass Total Custom BFGS! | 1 1 iter 0, current loss=4.0 iter 1, current loss=1.0 ================ STEP 0 =============== Test Summary: | Pass Total var_to_bounds | 1 1 Test Summary: | Pass Total newton_raphson_with_grad | 3 3 Test Summary: | Pass Total pack and unpack | 2 2 Test Summary: | Pass Total search direction | 1 1 iter 1, current loss = 31.41873623749015 ================== STEP 0 ================== iter 2, current loss = 9.421227507465258e6 iter 3, current loss = 26.63554318541166 iter 4, current loss = 0.7869181517441398 ================== STEP 1 ================== iter 5, current loss = 0.7576508420793803 iter 6, current loss = 0.9672547725127995 iter 7, current loss = 0.7552105289583271 ================== STEP 2 ================== iter 8, current loss = 0.7356363398999671 iter 9, current loss = 0.6600585219147992 iter 10, current loss = 1.0124696262381863 iter 11, current loss = 0.6080860806609445 ================== STEP 3 ================== iter 12, current loss = 3.8479930547132146 iter 13, current loss = 0.5878426066647625 iter 14, current loss = 0.6378324742528356 iter 15, current loss = 0.5475663907691561 ================== STEP 4 ================== iter 16, current loss = 0.48774447778505836 iter 17, current loss = 0.48576226981102855 ================== STEP 5 ================== iter 18, current loss = 0.3932864815835869 iter 19, current loss = 0.3069764154139901 iter 20, current loss = 0.28369874330659106 ================== STEP 6 ================== iter 21, current loss = 0.26896457448842315 iter 22, current loss = 0.23476352497423075 ================== STEP 7 ================== iter 23, current loss = 0.1565153795359934 iter 24, current loss = 7.7902059171044735 iter 25, current loss = 0.15607501559674974 ================== STEP 8 ================== iter 26, current loss = 0.14168683783974695 iter 27, current loss = 0.13579926305438336 ================== STEP 9 ================== iter 28, current loss = 0.0841290483973924 iter 29, current loss = 0.22472136215701558 iter 30, current loss = 0.06434913893555012 ================== STEP 10 ================== iter 31, current loss = 0.04092814936265465 iter 32, current loss = 0.005399276931010971 iter 33, current loss = 35.88236380450396 iter 34, current loss = 0.005224104424433896 ================== STEP 11 ================== iter 35, current loss = 2.525303461086011 iter 36, current loss = 0.0038172277978073777 ================== STEP 12 ================== iter 37, current loss = 0.0012033966577810085 iter 38, current loss = 0.001104827430824058 ================== STEP 13 ================== iter 39, current loss = 0.0007703894352359878 iter 40, current loss = 0.0012682000653405088 iter 41, current loss = 0.0005767250997462312 ================== STEP 14 ================== iter 42, current loss = 0.00012648246479401878 iter 43, current loss = 0.0010147384683644725 iter 44, current loss = 1.8817019421980154e-5 ================== STEP 15 ================== iter 45, current loss = 1.223628371356556e-6 iter 46, current loss = 1.206832267965777e-6 ================== STEP 16 ================== iter 47, current loss = 1.0125251044949235e-9 iter 48, current loss = 3.451113162715698e-10 ================== STEP 17 ================== iter 49, current loss = 4.4193311884385034e-14 iter 50, current loss = 4.050063503351649e-14 ================== STEP 18 ================== iter 51, current loss = 2.0788415055304255e-19 iter 52, current loss = 6.443444393193225e-13 iter 53, current loss = 1.5710177204124288e-23 ================== STEP 19 ================== iter 54, current loss = 0.0 ================== STEP 20 ================== iter 1, current loss = 31.41873623749015 ================== STEP 0 ================== iter 2, current loss = 88044.49474067306 iter 3, current loss = 10.324557145728383 ================== STEP 1 ================== iter 4, current loss = 8.660234908892937 iter 5, current loss = 0.7435995242720491 ================== STEP 2 ================== iter 6, current loss = 0.7375340184330207 iter 7, current loss = 0.7175701553315708 ================== STEP 3 ================== iter 8, current loss = 0.7105602294061514 iter 9, current loss = 39186.609581186545 iter 10, current loss = 0.7172077435989139 iter 11, current loss = 2450.561811844529 iter 12, current loss = 0.7157600874594378 iter 13, current loss = 153.00915181184396 iter 14, current loss = 0.7099972308171165 iter 15, current loss = 9.65177364186858 iter 16, current loss = 0.6874910931359037 iter 17, current loss = 0.9467890178686476 iter 18, current loss = 0.6112657479222497 iter 19, current loss = 0.5240659390923511 iter 20, current loss = 0.5216951143631857 ================== STEP 4 ================== iter 21, current loss = 0.7770448688322955 iter 22, current loss = 0.49326433624006166 ================== STEP 5 ================== iter 23, current loss = 0.48273351854745966 iter 24, current loss = 0.3150008529052397 ================== STEP 6 ================== iter 25, current loss = 0.3048245268779205 iter 26, current loss = 0.30313331661231047 ================== STEP 7 ================== iter 27, current loss = 0.3027666853338943 iter 28, current loss = 0.9311035731747701 iter 29, current loss = 0.27044738461131906 iter 30, current loss = 0.207350339181904 iter 31, current loss = 0.2032602335296662 ================== STEP 8 ================== iter 32, current loss = 14.891637391809667 iter 33, current loss = 0.19803327809488477 iter 34, current loss = 0.17996080906496414 ================== STEP 9 ================== iter 35, current loss = 0.078967720579138 iter 36, current loss = 0.06282016207825543 ================== STEP 10 ================== iter 37, current loss = 0.06203030309891009 iter 38, current loss = 0.05679627643191168 ================== STEP 11 ================== iter 39, current loss = 0.04015325241485707 iter 40, current loss = 1.5439929073157075 iter 41, current loss = 0.05291882073767225 iter 42, current loss = 0.07049463098782022 iter 43, current loss = 0.03686823290781953 iter 44, current loss = 0.015140988535987502 iter 45, current loss = 0.015141331276078994 ================== STEP 12 ================== iter 46, current loss = 0.012747515498596325 iter 47, current loss = 0.012267454036271648 ================== STEP 13 ================== iter 48, current loss = 0.008988778199125311 iter 49, current loss = 0.002136229003854184 ================== STEP 14 ================== iter 50, current loss = 0.001982775475636184 iter 51, current loss = 0.0017744723319735322 ================== STEP 15 ================== iter 52, current loss = 0.0016766649787500474 iter 53, current loss = 0.000811900264048739 ================== STEP 16 ================== iter 54, current loss = 0.0016174276539537976 iter 55, current loss = 0.00019936423857933256 ================== STEP 17 ================== iter 56, current loss = 0.0001983123454003859 iter 57, current loss = 0.00019563049546848085 ================== STEP 18 ================== iter 58, current loss = 0.0001955098370177801 iter 59, current loss = 2.789788991618652e-6 ================== STEP 19 ================== iter 60, current loss = 0.07313076520063341 iter 61, current loss = 5.553318806912856e-7 ================== STEP 20 ================== iter 62, current loss = 4.7174414514093587e-7 iter 63, current loss = 3.751022267789017e-7 ================== STEP 21 ================== iter 64, current loss = 3.7504034942091634e-7 iter 65, current loss = 2.9457958113082e-10 ================== STEP 22 ================== iter 66, current loss = 6.505447725950654e-5 iter 67, current loss = 5.266112178122424e-13 ================== STEP 23 ================== iter 68, current loss = 5.263353322139138e-13 iter 69, current loss = 5.254798810461212e-13 ================== STEP 24 ================== iter 70, current loss = 5.245760184729856e-13 iter 71, current loss = 6.665895054348392e-21 ================== STEP 25 ================== iter 72, current loss = 1.6751813805029995e-19 iter 73, current loss = 6.641150980453462e-21 ================== STEP 26 ================== Test Summary: | Pass Total Optim | 2 2 [2.687340311058956, 2.2848777584058286, 1.9594851778940723, 1.695402405085309, 1.480263493197685, 1.3043185081551039, 1.1598475045894157, 1.0407152651051803, 0.9420302552703157, 0.8598815076342152] [2.687340311058956, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.480263454379844, 1.3043184684311484, 1.1598474654062378, 1.0407152273674067, 0.9420302195019172, 0.8598814740954399] [2.687340311058956, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722337, 1.7903868796137, 1.666533106551471, 1.5498999348193685, 1.4403938823398204] [2.687340311058956, 2.5196803722971532, 2.3591806721463433, 2.2059490607905308, 2.060059325290666, 1.921544648411781, 1.7903894445161121, 1.6665356793266157, 1.5499024452536936, 1.4403964019318742] [2.687340311058956, 2.519680334828145, 2.407655825231478, 2.3197815374114255, 2.246150283167248, 2.182163783773478, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252] [2.687340311058956, 2.5289466959494193, 2.420490642269894, 2.3345738165870626, 2.262184980528145, 2.1990517443624436, 2.1427536022001736, 2.0917631683139017, 2.0450438762274734, 2.001854279772373] [2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956] [2.687340311058956, 2.6872637777504984, 2.687186271558512, 2.6871081082446744, 2.6870294441458276, 2.6869503723706383, 2.6868709546007827, 2.6867912346415768, 2.686711245167153, 2.6866310114542364] ADCME.Optimizer.RMSProp: [2.687340311058956, 2.1809229506849572, 1.8767079801297724, 1.6546592408302834, 1.4792440330627719, 1.334696176675614, 1.212439851596489, 1.1071870862263171, 1.0154089446876469, 0.9346163191023282] ADCME.Optimizer.AMSGrad: [2.687340311058956, 2.1809312707347455, 1.6124928714759128, 1.1086151780363889, 0.7379095523937292, 0.5260637392759809, 0.45851612395000907, 0.4877499962958967, 0.5512317022689823, 0.5952183172262842] ADCME.Optimizer.NADAM: [2.687340311058956, 2.442570256533514, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870794, 1.3669096060903076] ADCME.Optimizer.Momentum: [2.687340311058956, 0.5561138694752266, 1.9019191744859019, 1.5251751312785737, 0.0420157941282293, 1.1070655728753587, 0.9972859136071748, 0.09250596740575295, 0.8373703084967704, 0.9155307151492695] ADCME.Optimizer.Nesterov: [2.687340311058956, 1.9593498023002809, 1.2701537117986892, 0.7838060906690361, 0.5406336834135216, 0.4889865362290184, 0.5361697434507272, 0.593802848884102, 0.6052577936273842, 0.5531368580544891] ADCME.Optimizer.RADAM: [2.687340311058956, 2.2848777584058286, 1.94323977812989, 1.6552856125616953, 1.4144226819237642, 1.4126078826685302, 1.4099249144610229, 1.4065453158264798, 1.4025672017224884, 1.3980581649489405] ADCME.Optimizer.AdaMax: [2.687340311058956, 2.51968033219294, 2.362208211311266, 2.2144819560814186, 2.0760592333976766, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.606666358477995, 1.5082598767767736] Test Summary: | Pass Total Optimizers | 4 4 Test Summary: | Pass Total sinkhorn | 1 1 Test Summary: | Pass Total dist | 5 5 Test Summary: | Pass Total runge_kutta | 6 6 Test Summary: | Pass Total alpha scheme | 2 2 Test Summary: | Pass Total LinearFlow | 2 2 Test Summary: | Pass Total AffineConstantFlow | 2 2 Test Summary: | Pass Total ActNorm | 2 2 Test Summary: | Pass Total SlowMAF | 2 2 Test Summary: | Pass Total MAF | 2 2 Test Summary: | Pass Total IAF | 2 2 Test Summary: | Pass Total Invertible1x1Conv | 2 2 Test Summary: | Pass Total AffineHalfFlow | 2 2 Test Summary: | Pass Total NeuralCouplingFlow | 2 2 Test Summary: | Pass Total Permute | 2 2 Test Summary: | Pass Total composite | 2 2
