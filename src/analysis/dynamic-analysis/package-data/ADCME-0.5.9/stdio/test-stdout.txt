### DYNAMIC ANALYSIS LINE IDENTIFIER ###
/home/jack/bin/julia
[✔️] Julia version
[✔️] TensorFlow version
[✔️] TensorFlow-Probability version
[✔️] Python executable file
[✔️] Julia path
[✘] Dynamic library path (Optional)

[Reason]
/home/jack/.julia/conda/3/lib is not in LD_LIBRARY_PATH. This MAY break custom operator compilation. However, in most cases, ADCME automatic fixes this problem for you.


[Instruction]
Add your dynamic library path path to your environment path, e.g. (Unix systems) 

export LD_LIBRARY_PATH=/home/jack/.julia/conda/3/lib:$LD_LIBRARY_PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux or Apple).
For Windows, you need to add it to PATH instead of LD_LIBRARY_PATH.

[✔️] Memory Address Length =  64
[✘] Binaries path

[Reason]
/home/jack/.julia/conda/3/bin is not in PATH. This path contains compatible tools such as a GCC compiler, `cmake`, `make`, or any other tools you want to use directly from terminal.
However, setting the path is NOT a requirement, and ADCME works totally fine without any action.


[Instruction]
(Optional) Add your binary path to your environment path, e.g. (Unix systems) 

export PATH=/home/jack/.julia/conda/3/bin:$PATH

For convenience, you can add the above line to your `~/.bashrc` (Linux) or `~/.bash_profile` (Apple).
For Windows, you need to add it to system environment.

[✘] GPU Support (Optional)

[Reason]
ADCME is not compiled against GPU.


[Instruction]
If you intend to use GPU, set ENV["GPU"] = 1 and then rebuild ADCME.

Dependency file is located at: /home/jack/.julia/packages/ADCME/DBZ10/src/../deps/deps.jl
Test Summary:               | Pass  Total
indexing for rank 3 tensors |    3      3
Load library operator (with gradient, multiple outputs = true): /home/jack/.julia/packages/ADCME/DBZ10/deps/Plugin/ExtendedNN/build/libExtendedNn.so ==> extended_nn
Test Summary: | Pass  Total
fcx           |    4      4
Test Summary: | Pass  Total
dropout       |    2      2
Test Summary:      | Pass  Total
sparse_constructor |    7      7
Test Summary:     | Pass  Total
sparse_arithmetic |    4      4
Test Summary:  | Pass  Total
sparse_adjoint |    1      1
Test Summary: | Pass  Total
sparse_mul    |    6      6
Test Summary:    | Pass  Total
sparse_vcat_hcat |    2      2
Test Summary:   | Pass  Total
sparse_indexing |    3      3
Test Summary: | Pass  Total
sparse_solve  |    1      1
k = 1
k = 2
k = 3
k = 4
k = 5
k = 6
k = 7
k = 8
k = 9
k = 10
v = [0.5875759105731149, 0.6636075289255532, 0.7675828932337916, 0.6243739207995518, 0.20750880639086833, 0.417787272602665, 0.42927969168592184, 0.46344660045822494, 0.9532578984431337, 0.2786441081710682]
Test Summary:    | Pass  Total
sparse_assembler |    3      3
Test Summary:       | Pass  Total
sparse_least_square |    1      1
Test Summary:  | Pass  Total
sparse mat mul |    3      3
Test Summary: | Pass  Total
spdiag        |    3      3
Test Summary: | Pass  Total
spzero        |    2      2
Test Summary:   | Pass  Total
sparse indexing |    1      1
Test Summary: | Pass  Total
sum           |    3      3
Test Summary:   | Pass  Total
dense_to_sparse |    2      2
Test Summary: | Pass  Total
spdiagm       |    4      4
Test Summary: | Pass  Total
hvcat         |    1      1
Test Summary: | Pass  Total
find          |    6      6
Test Summary:             | Pass  Total
sparse scatter update add |    2      2
Test Summary:   | Pass  Total
constant sparse |    1      1
Test Summary: | Pass  Total
get index     |    1      1
Test Summary:                  | Pass  Total
sparse_factorization_and_solve |    2      2
Test Summary:         | Pass  Total
sparse solver warning |    1      1
Test Summary:  | Pass  Total
sparse promote |    6      6
Test Summary: | Broken  Total
random        |     47     47
Test Summary: | Pass  Total
save and load |    1      1
Test Summary:   | Pass  Total
psave and pload |    1      1
tensorboard --logdir="/tmp/jl_B5SYF8" --port 0
tensorboard --logdir="/tmp/jl_79Zehd" --port 0
Test Summary: |
diary         | No tests
Test Summary: | Pass  Total
indexing      |   28     28
Test Summary: | Pass  Total
Variables     |    4      4
Test Summary: | Pass  Total
tensor        |    2      2
Test Summary: | Pass  Total
Hessian       |    2      2
Test Summary: | Pass  Total
Jacobian      |    1      1
Test Summary: | Pass  Total
gradients_v   |    1      1
Test Summary:   | Pass  Total
size and length |    9      9
Test Summary: | Pass  Total
copy          |    1      1
Test Summary: | Pass  Total
getindex      |    1      1
Test Summary:     | Pass  Total
convert_to_tensor |    5      5
Test Summary: | Pass  Total
cell          |    2      2
Test Summary:    | Pass  Total
special matrices |    2      2
Test Summary:   | Pass  Total
ones/zeros like |    2      2
Test Summary:      | Pass  Total
gradient_magnitude |    1      1
Test Summary:        | Pass  Total
indexing with tensor |    6      6
Test Summary: | Pass  Total
ndims         |    4      4
Test Summary:      | Pass  Total
gradients_colocate |    1      1
Test Summary: | Pass  Total
*             |   27     27
Test Summary: | Pass  Total
reshape       |    6      6
Test Summary:  | Pass  Total
scatter_update |    9      9
Test Summary: | Pass  Total
adjoint       |    4      4
Test Summary:           | Pass  Total
scatter_update_pyobject |    9      9
Test Summary: | Pass  Total
Operators     |   14     14
Test Summary:   | Pass  Total
Other Operators |    1      1
Test Summary:    | Pass  Total
Concat and stack |    6      6
Test Summary: | Pass  Total
Vectorize     |    5      5
Test Summary: | Pass  Total
Solve         |    3      3
Test Summary: | Pass  Total
diff          |    3      3
Test Summary: | Pass  Total
clip          |    1      1
Test Summary: | Pass  Total
map           |    1      1
Test Summary: | Pass  Total
diag          |    2      2
Test Summary: | Pass  Total
dot           |    3      3
Test Summary: | Pass  Total
prod          |    1      1
Test Summary: | Pass  Total
findall       |    2      2
Test Summary: | Pass  Total
svd           |    1      1
Test Summary: | Pass  Total
vector        |    1      1
Test Summary: | Pass  Total
repeat        |    6      6
Test Summary: | Pass  Total
pmap          |    3      3
Test Summary: | Pass  Total
reshape       |    1      1
Test Summary: | Pass  Total
batch mul     |    1      1
Test Summary: | Pass  Total
sort          |    2      2
Test Summary: | Pass  Total
set_shape     |    3      3
Test Summary: | Pass  Total
activation    |    8      8
Test Summary: | Pass  Total
trace         |    1      1
Test Summary: | Pass  Total
trilu         |   22     22
Test Summary: | Pass  Total
reverse       |    3      3
Test Summary: | Pass  Total
solve batch   |    2      2
Test Summary:      | Pass  Total
control_dependency |    2      2
Test Summary: | Pass  Total
while loop    |    3      3
Test Summary: | Pass  Total
if_clause     |    1      1
Test Summary:     | Pass  Total
if_else: tf.where |    2      2
Test Summary:          | Pass  Total
get and add collection |    1      1
Test Summary: | Pass  Total
has_gpu       |    1      1
Test Summary: |
timeline      | No tests
Test Summary: | Pass  Total
independent   |    1      1
Test Summary:    | Pass  Total
run corner cases |    1      1
Test Summary: | Pass  Total
@cpu @gpu     |    4      4
Test Summary: | Pass  Total
xavier_init   |    1      1
Load library operator: /home/jack/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Load library operator (with gradient, multiple outputs = false): /home/jack/.julia/packages/ADCME/DBZ10/deps/CustomOps/build/libadcme.so ==> sparse_solver
Test Summary: | Pass  Total
load_op       |    2      2
Test Summary: | Pass  Total
ae            |    1      1
Test Summary: | Pass  Total
register      |    4      4
Test Summary:         | Pass  Total
list_physical_devices |    1      1
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.0], 6, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([2.0945514815423265], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9708700202758002], 6, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.7390849812432807], 21, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.9999997106416106], 19, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([1.299999999999859], 42, true)
((nrr[i]).x, (nrr[i]).iter, (nrr[i]).converged) = ([0.4584075016314119], 23, true)
Test Summary:                  | Pass  Total
newton raphson with linesearch |    7      7
[CustomOptimizer] Number of inequalities constraints = 1, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 4
Test Summary: | Pass  Total
NLopt         |    1      1
[CustomOptimizer] Number of inequalities constraints = 0, Number of equality constraints = 0
[CustomOptimizer] Total number of variables = 2
[CustomOptimizer] No bounds provided, use (-∞, +∞) as default; or you need to provide bounds in the function CustomOptimizer
(f, df, c, dc, x0) = (ADCME.var"#f#468"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f08cc39b5f0>), ADCME.var"#df#469"{PyObject}(PyObject <function ExternalOptimizerInterface._make_eval_func.<locals>.eval_func at 0x7f08cc39b5f0>), ADCME.var"#c#470"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64}([0.5875759105731149, 0.6636075289255532], Any[], Any[], 0, 0), ADCME.var"#dc#473"{Array{Float64,1},Array{Any,1},Array{Any,1},Int64,Int64,Int64,Int64}([0.5875759105731149, 0.6636075289255532], Any[], Any[], 0, 0, 2, 0), [0.5875759105731149, 0.6636075289255532])
Test Summary: | Pass  Total
Optim         |    1      1
Test Summary:  | Broken  Total
newton raphson |      1      1
Test Summary:               | Broken  Total
NonlinearConstrainedProblem |      1      1
iter 1, current loss = 9487.908283299315
================== STEP 0 ==================
iter 2, current loss = 8.659905644897122e11
iter 3, current loss = 3202.1440023644936
================== STEP 1 ==================
iter 4, current loss = 2968.2203006788372
iter 5, current loss = 2284.3965298830544
iter 6, current loss = 4910.182538628618
iter 7, current loss = 1995.757646022485
================== STEP 2 ==================
iter 8, current loss = 1989.2369805842422
iter 9, current loss = 1963.261016857753
iter 10, current loss = 1835.941950860794
iter 11, current loss = 1263.3654367631252
iter 12, current loss = 0.9532634529312125
iter 13, current loss = 8.1000926768812e-21
================== STEP 3 ==================
iter 14, current loss = 4.907092692008395e-18
iter 15, current loss = 8.046114682868468e-21
================== STEP 4 ==================
Test Summary: | Pass  Total
Custom BFGS!  |    1      1
iter 0, current loss=4.0
iter 1, current loss=1.0
================ STEP 0 ===============
Test Summary: | Pass  Total
var_to_bounds |    1      1
Test Summary:            | Pass  Total
newton_raphson_with_grad |    3      3
Test Summary:   | Pass  Total
pack and unpack |    2      2
Test Summary:    | Pass  Total
search direction |    1      1
iter 1, current loss = 4.922623925822989
================== STEP 0 ==================
iter 2, current loss = 2.942821794020991e9
iter 3, current loss = 4.917850671155219
iter 4, current loss = 0.12590369110984664
================== STEP 1 ==================
iter 5, current loss = 0.06446466126373601
iter 6, current loss = 0.7419090983079967
iter 7, current loss = 0.06348869213192808
================== STEP 2 ==================
iter 8, current loss = 0.06336778808715149
iter 9, current loss = 0.06293629832928314
iter 10, current loss = 0.062065579464798064
iter 11, current loss = 0.062053777053686886
================== STEP 3 ==================
iter 12, current loss = 0.05950162975033262
iter 13, current loss = 0.05029882992152574
iter 14, current loss = 0.04721964287536605
iter 15, current loss = 0.03774408096837635
================== STEP 4 ==================
iter 16, current loss = 0.020270667396982002
iter 17, current loss = 0.5264636615146461
iter 18, current loss = 0.01953644893354591
================== STEP 5 ==================
iter 19, current loss = 0.0088216767605926
iter 20, current loss = 0.008802568888801385
================== STEP 6 ==================
iter 21, current loss = 0.0038069341554815552
iter 22, current loss = 0.003043688427157958
================== STEP 7 ==================
iter 23, current loss = 0.002281975313272675
iter 24, current loss = 0.0017658872493839196
================== STEP 8 ==================
iter 25, current loss = 0.0007294310456502762
iter 26, current loss = 0.001688052705019033
iter 27, current loss = 0.00018977052639143543
================== STEP 9 ==================
iter 28, current loss = 5.8076733724420364e-5
iter 29, current loss = 1.0987182391315926e-5
================== STEP 10 ==================
iter 30, current loss = 1.35589359903297e-6
iter 31, current loss = 5.3590004869832456e-5
iter 32, current loss = 9.352152830804078e-10
================== STEP 11 ==================
iter 33, current loss = 1.18943459820788e-12
iter 34, current loss = 1.369504280853983e-8
iter 35, current loss = 3.8615973683246304e-14
================== STEP 12 ==================
iter 36, current loss = 2.9389837536738584e-17
iter 37, current loss = 1.853910994738521e-21
================== STEP 13 ==================
iter 38, current loss = 2.2803010541544873e-28
iter 39, current loss = 1.232595164407831e-32
================== STEP 14 ==================
iter 1, current loss = 4.922623925822989
================== STEP 0 ==================
iter 2, current loss = 3.6031713794068494e6
iter 3, current loss = 4.778327742909966
iter 4, current loss = 0.12433993424718812
================== STEP 1 ==================
iter 5, current loss = 0.10669390042526883
iter 6, current loss = 0.06353278397067305
================== STEP 2 ==================
iter 7, current loss = 0.0635058049954123
iter 8, current loss = 0.06308387436562131
================== STEP 3 ==================
iter 9, current loss = 0.06210538395289053
iter 10, current loss = 0.6898741150797358
iter 11, current loss = 0.05612237944666399
iter 12, current loss = 0.5492737766154814
iter 13, current loss = 0.052576695645736055
iter 14, current loss = 0.03837835204683858
================== STEP 4 ==================
iter 15, current loss = 0.949711719841821
iter 16, current loss = 0.03574103786446542
iter 17, current loss = 0.03475428155318229
================== STEP 5 ==================
iter 18, current loss = 0.019568847611513982
iter 19, current loss = 0.006922886407290293
================== STEP 6 ==================
iter 20, current loss = 0.006762773036425935
iter 21, current loss = 0.006514129712854776
================== STEP 7 ==================
iter 22, current loss = 0.006237401850867535
iter 23, current loss = 0.02265905077693416
iter 24, current loss = 0.0035835099782308925
================== STEP 8 ==================
iter 25, current loss = 0.0028329977946301363
iter 26, current loss = 0.0025111030220251285
================== STEP 9 ==================
iter 27, current loss = 0.0022591524151891443
iter 28, current loss = 0.00030536395036456825
================== STEP 10 ==================
iter 29, current loss = 0.00021876913076411485
iter 30, current loss = 7.362884314916166e-5
================== STEP 11 ==================
iter 31, current loss = 7.155757234439587e-6
iter 32, current loss = 8.687134771320815e-7
================== STEP 12 ==================
iter 33, current loss = 6.179304356332575e-7
iter 34, current loss = 1.2329056251832263e-8
================== STEP 13 ==================
iter 35, current loss = 1.0677739570874647e-8
iter 36, current loss = 1.1281993251561466e-10
================== STEP 14 ==================
iter 37, current loss = 1.3075991750537189e-11
iter 38, current loss = 1.2743917967632096e-11
================== STEP 15 ==================
iter 39, current loss = 1.274186213357903e-11
iter 40, current loss = 2.756524295359467e-16
================== STEP 16 ==================
iter 41, current loss = 2.221455235483834e-12
iter 42, current loss = 2.66017092646334e-16
================== STEP 17 ==================
iter 43, current loss = 2.659706994539921e-16
iter 44, current loss = 7.366639402585552e-19
================== STEP 18 ==================
iter 45, current loss = 1.8224378022314004e-18
iter 46, current loss = 7.227125655393969e-19
================== STEP 19 ==================
iter 47, current loss = 5.01045749511653e-19
iter 48, current loss = 2.72398600953473e-27
================== STEP 20 ==================
iter 49, current loss = 2.3645716133927876e-25
iter 50, current loss = 3.9553978825847295e-29
================== STEP 21 ==================
Test Summary: | Pass  Total
Optim         |    2      2
[2.687340311058956, 2.2848777584058286, 1.9594851778940723, 1.695402405085309, 1.480263493197685, 1.3043185081551039, 1.1598475045894157, 1.0407152651051803, 0.9420302552703157, 0.8598815076342152]
[2.687340311058956, 2.284877740310942, 1.959485148600987, 1.6954023693861155, 1.480263454379844, 1.3043184684311484, 1.1598474654062378, 1.0407152273674067, 0.9420302195019172, 0.8598814740954399]
[2.687340311058956, 2.51968033219294, 2.3591800737664697, 2.2059474319979726, 2.060057321374523, 1.9215424113722337, 1.7903868796137, 1.666533106551471, 1.5498999348193685, 1.4403938823398204]
[2.687340311058956, 2.5196803722971532, 2.3591806721463433, 2.2059490607905308, 2.060059325290666, 1.921544648411781, 1.7903894445161121, 1.6665356793266157, 1.5499024452536936, 1.4403964019318742]
[2.687340311058956, 2.519680334828145, 2.407655825231478, 2.3197815374114255, 2.246150283167248, 2.182163783773478, 2.1252505434992806, 2.0738022333150226, 2.0267344163791177, 1.9832752878804252]
[2.687340311058956, 2.5289466959494193, 2.420490642269894, 2.3345738165870626, 2.262184980528145, 2.1990517443624436, 2.1427536022001736, 2.0917631683139017, 2.0450438762274734, 2.001854279772373]
[2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956, 2.687340311058956]
[2.687340311058956, 2.6872637777504984, 2.687186271558512, 2.6871081082446744, 2.6870294441458276, 2.6869503723706383, 2.6868709546007827, 2.6867912346415768, 2.686711245167153, 2.6866310114542364]
ADCME.Optimizer.RMSProp: 
[2.687340311058956, 2.1809229506849572, 1.8767079801297724, 1.6546592408302834, 1.4792440330627719, 1.334696176675614, 1.212439851596489, 1.1071870862263171, 1.0154089446876469, 0.9346163191023282]
ADCME.Optimizer.AMSGrad: 
[2.687340311058956, 2.1809312707347455, 1.6124928714759128, 1.1086151780363889, 0.7379095523937292, 0.5260637392759809, 0.45851612395000907, 0.4877499962958967, 0.5512317022689823, 0.5952183172262842]
ADCME.Optimizer.NADAM: 
[2.687340311058956, 2.442570256533514, 2.2636223209469, 2.1059931830955145, 1.9611223452288686, 1.8261560639124625, 1.699821585350836, 1.5814319739611475, 1.4705621558870794, 1.3669096060903076]
ADCME.Optimizer.Momentum: 
[2.687340311058956, 0.5561138694752266, 1.9019191744859019, 1.5251751312785737, 0.0420157941282293, 1.1070655728753587, 0.9972859136071748, 0.09250596740575295, 0.8373703084967704, 0.9155307151492695]
ADCME.Optimizer.Nesterov: 
[2.687340311058956, 1.9593498023002809, 1.2701537117986892, 0.7838060906690361, 0.5406336834135216, 0.4889865362290184, 0.5361697434507272, 0.593802848884102, 0.6052577936273842, 0.5531368580544891]
ADCME.Optimizer.RADAM: 
[2.687340311058956, 2.2848777584058286, 1.94323977812989, 1.6552856125616953, 1.4144226819237642, 1.4126078826685302, 1.4099249144610229, 1.4065453158264798, 1.4025672017224884, 1.3980581649489405]
ADCME.Optimizer.AdaMax: 
[2.687340311058956, 2.51968033219294, 2.362208211311266, 2.2144819560814186, 2.0760592333976766, 1.9464997124427983, 1.8253670164593165, 1.7122304206311472, 1.606666358477995, 1.5082598767767736]
Test Summary: | Pass  Total
Optimizers    |    4      4
Test Summary: | Pass  Total
sinkhorn      |    1      1
Test Summary: | Pass  Total
dist          |    5      5
Test Summary: | Pass  Total
runge_kutta   |    6      6
Test Summary: | Pass  Total
alpha scheme  |    2      2
Test Summary: | Pass  Total
LinearFlow    |    2      2
Test Summary:      | Pass  Total
AffineConstantFlow |    2      2
Test Summary: | Pass  Total
ActNorm       |    2      2
Test Summary: | Pass  Total
SlowMAF       |    2      2
Test Summary: | Pass  Total
MAF           |    2      2
Test Summary: | Pass  Total
IAF           |    2      2
Test Summary:     | Pass  Total
Invertible1x1Conv |    2      2
Test Summary:  | Pass  Total
AffineHalfFlow |    2      2
Test Summary:      | Pass  Total
NeuralCouplingFlow |    2      2
Test Summary: | Pass  Total
Permute       |    2      2
Test Summary: | Pass  Total
composite     |    2      2
